# Solo

[![NPM Version](https://img.shields.io/npm/v/%40hashgraph%2Fsolo?logo=npm)](https://www.npmjs.com/package/@hashgraph/solo)
[![GitHub License](https://img.shields.io/github/license/hashgraph/solo?logo=apache\&logoColor=red)](LICENSE)
![node-lts](https://img.shields.io/node/v-lts/%40hashgraph%2Fsolo)
[![Build Application](https://github.com/hashgraph/solo/actions/workflows/flow-build-application.yaml/badge.svg)](https://github.com/hashgraph/solo/actions/workflows/flow-build-application.yaml)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/83a423a3a1c942459127b3aec62ab0b5)](https://app.codacy.com/gh/hashgraph/solo/dashboard?utm_source=gh\&utm_medium=referral\&utm_content=\&utm_campaign=Badge_grade)
[![codecov](https://codecov.io/gh/hashgraph/solo/graph/badge.svg?token=hBkQdB1XO5)](https://codecov.io/gh/hashgraph/solo)

An opinionated CLI tool to deploy and manage standalone test networks.

## Table of Contents

* [Requirements](#requirements)
* [Setup](#setup)
* [Install Solo](#install-solo)
* [Setup Kubernetes cluster](#setup-kubernetes-cluster)
* [Generate Node Keys](#generate-node-keys)
  * [Legacy keys (.pfx file)](#legacy-keys-pfx-file)
  * [Standard keys (.pem file)](#standard-keys-pem-file)
* [Examples](#examples)
  * [Example - 1: Deploy a standalone test network (version `0.42.5`)](#example---1-deploy-a-standalone-test-network-version-0425)
  * [Example - 2: Deploy a standalone test network (version `0.47.0-alpha.0`)](#example---2-deploy-a-standalone-test-network-version-0470-alpha0)
* [Support](#support)
* [Contributing](#contributing)
* [Code of Conduct](#code-of-conduct)
* [License](#license)

## Requirements

* Node(>=20.14.0) (*lts/hydrogen*)

## Setup

* Install [Node](https://nodejs.org/en/download). You may also use [nvm](https://github.com/nvm-sh/nvm) to manage different Node versions locally:

```
nvm install lts/hydrogen
nvm use lts/hydrogen 
```

* Useful tools:
  * Install [kubectl](https://kubernetes.io/docs/tasks/tools/)
  * Install [k9s](https://k9scli.io/)

## Install Solo

* Run `npm install -g @hashgraph/solo`

## Setup Kubernetes cluster

### Remote cluster

* You may use remote kubernetes cluster. In this case, ensure kubernetes context is set up correctly.

```
kubectl config use-context <context-name>
```

### Local cluster

* You may use [kind](https://kind.sigs.k8s.io/) or [microk8s](https://microk8s.io/) to create a cluster. In this case,
  ensure your Docker engine has enough resources (e.g. Memory >=8Gb, CPU: >=4). Below we show how you can use `kind` to create a cluster

First, use the following command to set up the environment variables:

```
export SOLO_CLUSTER_NAME=solo
export SOLO_NAMESPACE=solo
export SOLO_CLUSTER_SETUP_NAMESPACE=solo-cluster
```

Then run the following command to set the kubectl context to the new cluster:

```bash
kind create cluster -n "${SOLO_CLUSTER_NAME}"
```
Example output

```
Creating cluster "solo" ...
 âœ“ Ensuring node image (kindest/node:v1.29.1) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦ 
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing CNI ğŸ”Œ
 âœ“ Installing StorageClass ğŸ’¾
Set kubectl context to "kind-solo"
You can now use your cluster with:

kubectl cluster-info --context kind-solo

Thanks for using kind! ğŸ˜Š
```

You may now view pods in your cluster using `k9s -A` as below:

```
 Context: kind-solo                                <0> all       <a>      Attacâ€¦ ____  __.________
 Cluster: kind-solo                                <1> default   <ctrl-d> Delete|    |/ _/   __   \______
 User:    kind-solo                                              <d>      Descri|      < \____    /  ___/
 K9s Rev: v0.27.4 âš¡ï¸v0.32.3                                      <e>      Edit  |    |  \   /    /\___ \
 K8s Rev: v1.27.3                                                <?>      Help  |____|__ \ /____//____  >
 CPU:     n/a                                                    <ctrl-k> Kill          \/            \/
 MEM:     n/a
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pods(all)[9] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NAMESPACEâ†‘          NAME                                        PF READY RESTARTS STATUS   IP          â”‚
â”‚ kube-system         coredns-5d78c9869d-kc27p                    â—  1/1          0 Running  10.244.0.4  â”‚
â”‚ kube-system         coredns-5d78c9869d-r8mzz                    â—  1/1          0 Running  10.244.0.3  â”‚
â”‚ kube-system         etcd-solo-control-plane                     â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ kube-system         kindnet-gppbk                               â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ kube-system         kube-apiserver-solo-control-plane           â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ kube-system         kube-controller-manager-solo-control-plane  â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ kube-system         kube-proxy-wb9w5                            â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ kube-system         kube-scheduler-solo-control-plane           â—  1/1          0 Running  172.18.0.2  â”‚
â”‚ local-path-storage  local-path-provisioner-6bc4bddd6b-5vh5d     â—  1/1          0 Running  10.244.0.2  â”‚
â”‚                                                                                                        â”‚
â”‚ 
```

## Examples

### Example - 1: Deploy a standalone test network (version `0.42.5`)

* Initialize `solo` with tag `v0.42.5` and list of node names `node0,node1,node2`:

```
$ solo init -t v0.42.5 -i node0,node1,node2 -n "${SOLO_NAMESPACE}" -s "${SOLO_CLUSTER_SETUP_NAMESPACE}" --key-format pfx 
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Setup home directory and cache
âœ” Check dependency: helm [OS: linux, Release: 5.15.0-1061-gke, Arch: x64]
âœ” Check dependencies
âœ” Setup chart manager

***************************************************************************************
Note: solo stores various artifacts (config, logs, keys etc.) in its home directory: /home/runner/.solo
If a full reset is needed, delete the directory or relevant sub-directories before running 'solo init'.
***************************************************************************************
âœ” Copy templates in '/home/runner/.solo/cache'
```

* Generate `pfx` formatted node keys

We need to generate `pfx` keys as `pem` key files are only supported by Hedera platform >=`0.47.0-alpha.0`.

```
$ solo node keys --gossip-keys --tls-keys --key-format pfx 
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Check keytool exists (Version: 21.0.1+12)
âœ” Backup old files
âœ” Generate private-node0.pfx for node: node0
âœ” Generate private-node1.pfx for node: node1
âœ” Generate private-node2.pfx for node: node2
âœ” Generate public.pfx file
âœ” Clean up temp files
âœ” Generate gossip keys
âœ” Backup old files
âœ” TLS key for node: node1
âœ” TLS key for node: node0
âœ” TLS key for node: node2
âœ” Generate gRPC TLS keys
âœ” Finalize
```
Key files are generated in `~/.solo/keys` directory.

```
$ ls ~/.solo/cache/keys 

hedera-node0.crt  hedera-node1.crt  hedera-node2.crt  private-node0.pfx private-node2.pfx
hedera-node0.key  hedera-node1.key  hedera-node2.key  private-node1.pfx public.pfx
```
* Setup cluster with shared components
  * In a separate terminal, you may run `k9s` to view the pod status.

```
$ solo cluster setup
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Prepare chart values
âœ” Install 'fullstack-cluster-setup' chart
```


* Deploy helm chart with Hedera network components
  * It may take a while (5~15 minutes depending on your internet speed) to download various docker images and get the pods started.
  * If it fails, ensure you have enough resources allocated for Docker engine and retry the command.

```
$ solo network deploy
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Install chart 'fullstack-deployment'
âœ” Check Node: node0
âœ” Check Node: node1
âœ” Check Node: node2
âœ” Check node pods are running
âœ” Check Envoy Proxy for: node1
âœ” Check Envoy Proxy for: node2
âœ” Check Envoy Proxy for: node0
âœ” Check HAProxy for: node1
âœ” Check HAProxy for: node2
âœ” Check HAProxy for: node0
âœ” Check proxy pods are running
âœ” Check MinIO
âœ” Check auxiliary pods are ready
```

* Setup node with Hedera platform software.
  * It may take a while as it download the hedera platform code from <https://builds.hedera.com/>

```
$ solo node setup
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Check network pod: node0
âœ” Check network pod: node2
âœ” Check network pod: node1
âœ” Identify network pods
âœ” Copy configuration files
âœ” Copy Gossip keys to staging
âœ” Copy gRPC TLS keys to staging
âœ” Prepare config.txt for the network
âœ” Prepare staging directory
âœ” Update node: node2
âœ” Update node: node1
âœ” Update node: node0
âœ” Fetch platform software into network nodes
âœ” Copy Gossip keys
âœ” Copy Gossip keys
âœ” Copy Gossip keys
âœ” Copy TLS keys
âœ” Copy TLS keys
âœ” Copy TLS keys
âœ” Copy configuration files
âœ” Copy configuration files
âœ” Copy configuration files
âœ” Set file permissions
âœ” Node: node1
âœ” Set file permissions
âœ” Node: node2
âœ” Set file permissions
âœ” Node: node0
âœ” Setup network nodes
âœ” Finalize
```

* Start the nodes.

```
$ solo node start
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Check network pod: node0
âœ” Check network pod: node2
âœ” Check network pod: node1
âœ” Identify network pods
âœ” Start node: node0
âœ” Start node: node1
âœ” Start node: node2
âœ” Starting nodes
âœ” Check node: node0
âœ” Check node: node1
âœ” Check node: node2
âœ” Check nodes are ACTIVE
âœ” Check proxy for node: node1
âœ” Check proxy for node: node0
âœ” Check proxy for node: node2
âœ” Check node proxies are ACTIVE
```
* Deploy mirror node

```
$ solo mirror-node deploy
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Prepare address book
âœ” Deploy mirror-node
âœ” Enable mirror-node
âœ” Check Hedera Explorer
âœ” Check Postgres DB
âœ” Check Monitor
âœ” Check GRPC
âœ” Check Importer
âœ” Check REST API
âœ” Check pods are ready
```

* Deploy a JSON RPC relay

```
$ solo relay deploy
```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Prepare chart values
âœ” Deploy JSON RPC Relay
âœ” Check relay is ready
```

You may view the list of pods using `k9s` as below:

```
 Context: kind-solo-e2e                            <0> all       <a>      Attach     <l>     â€¦ ____  __.________
 Cluster: kind-solo-e2e                            <1> default   <ctrl-d> Delete     <p>      |    |/ _/   __   \______
 User:    kind-solo-e2e                                          <d>      Describe   <shift-f>|      < \____    /  ___/
 K9s Rev: v0.27.4 âš¡ï¸v0.32.4                                      <e>      Edit       <s>      |    |  \   /    /\___ \
 K8s Rev: v1.27.3                                                <?>      Help       <n>      |____|__ \ /____//____  >
 CPU:     n/a                                                    <ctrl-k> Kill       <f>              \/            \/
 MEM:     n/a
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pods(all)[27] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NAMESPACEâ†‘          NAME                                                   PF READY RESTARTS STATUS   IP             â”‚
â”‚ fullstack-setup     console-557956d575-fqctd                               â—  1/1          0 Running  10.244.0.4     â”‚
â”‚ fullstack-setup     minio-operator-7d575c5f84-j9p6f                        â—  1/1          0 Running  10.244.0.3     â”‚
â”‚ kube-system         coredns-5d78c9869d-gknqp                               â—  1/1          0 Running  10.244.0.6     â”‚
â”‚ kube-system         coredns-5d78c9869d-q59pc                               â—  1/1          0 Running  10.244.0.5     â”‚
â”‚ kube-system         etcd-solo-e2e-control-plane                            â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ kube-system         kindnet-w9ps5                                          â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ kube-system         kube-apiserver-solo-e2e-control-plane                  â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ kube-system         kube-controller-manager-solo-e2e-control-plane         â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ kube-system         kube-proxy-p69z8                                       â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ kube-system         kube-scheduler-solo-e2e-control-plane                  â—  1/1          0 Running  172.18.0.2     â”‚
â”‚ local-path-storage  local-path-provisioner-6bc4bddd6b-8pkfk                â—  1/1          0 Running  10.244.0.2     â”‚
â”‚ solo                envoy-proxy-node0-84947f844f-f28tp                     â—  1/1          0 Running  10.244.0.215   â”‚
â”‚ solo                envoy-proxy-node1-65f8879dcc-j2lrk                     â—  1/1          0 Running  10.244.0.216   â”‚
â”‚ solo                envoy-proxy-node2-667f848689-dkmf9                     â—  1/1          0 Running  10.244.0.214   â”‚
â”‚ solo                fullstack-deployment-grpc-69f9cc5666-lf6ql             â—  1/1          0 Running  10.244.0.227   â”‚
â”‚ solo                fullstack-deployment-hedera-explorer-79f79b7df4-wjdct  â—  1/1          0 Running  10.244.0.226   â”‚
â”‚ solo                fullstack-deployment-importer-864489ffb8-6v8tk         â—  1/1          0 Running  10.244.0.228   â”‚
â”‚ solo                fullstack-deployment-postgres-postgresql-0             â—  1/1          0 Running  10.244.0.232   â”‚
â”‚ solo                fullstack-deployment-rest-584f5cb6bb-q9vnt             â—  1/1          0 Running  10.244.0.230   â”‚
â”‚ solo                fullstack-deployment-web3-69dcdfc4fb-mm5pk             â—  1/1          0 Running  10.244.0.229   â”‚
â”‚ solo                haproxy-node0-6969f76c77-n5cfl                         â—  1/1          1 Running  10.244.0.219   â”‚
â”‚ solo                haproxy-node1-59f6976d45-x6xmp                         â—  1/1          1 Running  10.244.0.217   â”‚
â”‚ solo                haproxy-node2-6df64d5457-hf9ps                         â—  1/1          1 Running  10.244.0.218   â”‚
â”‚ solo                minio-pool-1-0                                         â—  2/2          1 Running  10.244.0.224   â”‚
â”‚ solo                network-node0-0                                        â—  5/5          0 Running  10.244.0.221   â”‚
â”‚ solo                network-node1-0                                        â—  5/5          0 Running  10.244.0.222   â”‚
â”‚ solo                network-node2-0                                        â—  5/5          0 Running  10.244.0.220   â”‚
```

#### Access Hedera Network services

Once the nodes are up, you may now expose various services (using `k9s` (shift-f) or `kubectl port-forward`) and access. Below are most used services that you may expose.

* Node services: `network-<node ID>-svc`
* HAProxy: `haproxy-<node ID>-svc`
* Envoy Proxy: `envoy-proxy-<node ID>-svc`
* Hedera explorer: `fullstack-deployment-hedera-explorer`
* JSON Rpc Relays
  * You can deploy JSON RPC relays for one or more nodes as below:
  ```
  $ solo relay deploy -i node0,node1 
  ```

Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Prepare chart values
âœ” Deploy JSON RPC Relay
âœ” Check relay is ready
```

### Example - 2: Deploy a standalone test network (version `0.47.0-alpha.0`)

* Initialize `solo` with tag `v0.47.0-alpha.0` and list of node names `node0,node1,node2`:

```
# reset .solo directory
$ rm -rf ~/.solo 

$ solo init -t v0.47.0-alpha.0 -i node0,node1,node2 -n "${SOLO_NAMESPACE}" -s "${SOLO_CLUSTER_SETUP_NAMESPACE}" --key-format pem 
```

* Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Setup home directory and cache
âœ” Check dependency: helm [OS: linux, Release: 5.15.0-1061-gke, Arch: x64]
âœ” Check dependencies
âœ” Setup chart manager

***************************************************************************************
Note: solo stores various artifacts (config, logs, keys etc.) in its home directory: /home/runner/.solo
If a full reset is needed, delete the directory or relevant sub-directories before running 'solo init'.
***************************************************************************************
âœ” Copy templates in '/home/runner/.solo/cache'
```

* Generate `pem` formatted node keys

```
$ solo node keys --gossip-keys --tls-keys --key-format pem
```

* Example output

```

******************************* Solo *********************************************
Version			: 0.27.0
Kubernetes Context	: kind-solo
Kubernetes Cluster	: kind-solo
Kubernetes Namespace	: solo
**********************************************************************************
âœ” Initialize
âœ” Backup old files
âœ” Gossip pem key for node: node0
âœ” Gossip pem key for node: node1
âœ” Gossip pem key for node: node2
âœ” Generate gossip keys
âœ” Backup old files
âœ” TLS key for node: node2
âœ” TLS key for node: node0
âœ” TLS key for node: node1
âœ” Generate gRPC TLS keys
âœ” Finalize
```
PEM key files are generated in `~/.solo/keys` directory.
```
$ ls ~/.solo/cache/keys  
a-private-node0.pem a-public-node1.pem  hedera-node1.crt    s-private-node0.pem s-public-node1.pem
a-private-node1.pem a-public-node2.pem  hedera-node1.key    s-private-node1.pem s-public-node2.pem
a-private-node2.pem hedera-node0.crt    hedera-node2.crt    s-private-node2.pem
a-public-node0.pem  hedera-node0.key    hedera-node2.key    s-public-node0.pem
```
* Setup cluster with shared components

```
$ solo cluster setup

# output is similar to example-1 
```

In a separate terminal, you may run `k9s` to view the pod status.

* Deploy helm chart with Hedera network components

```
$ solo network deploy

# output is similar to example-1 
```

* Setup node with Hedera platform.
  * It may take a while (~10 minutes depending on your internet speed) to download various docker images and get the
    pods started.

```
$ solo node setup

# output is similar to example-1 
```

* Start the nodes

```
$ solo node start

# output is similar to example-1 
```
## For Developers Working on Hedera Service Repo

First, pleaes clone hedera service repo `https://github.com/hashgraph/hedera-services/` and build the code
with `./gradlew assemble`. If need to running nodes with different versions or releases, please duplicate the repo or build directories in
multiple directories, checkout to the respective version and build the code. 

To set customized `settings.txt` file, edit the file
`~/.solo/cache/templates/settings.txt` after `solo init` command.

Then you can start customized built hedera network with the following command:
```
solo node setup --local-build-path <default path to hedera repo>,node1=<custom build hedera repo>,node2=<custom build repo>
```

## For Developers Working on Platform core

To deploy node with local build PTT jar files, run the following command:
```
solo node setup --local-build-path <default path to hedera repo>,node1=<custom build hedera repo>,node2=<custom build repo>
 --app PlatformTestingTool.jar --app-config <path-to-test-json1,path-to-test-json2>
```
## Logs
You can find log for running solo command under the directory `~/.solo/logs/`
The file `solo.log` contains the logs for the solo command. 
The file `hashgraph-sdk.log` contains the logs from solo client when sending transactions to network nodes.


## Support

If you have a question on how to use the product, please see our [support guide](https://github.com/hashgraph/.github/blob/main/SUPPORT.md).

## Contributing

Contributions are welcome. Please see the [contributing guide](https://github.com/hashgraph/.github/blob/main/CONTRIBUTING.md) to see how you can get involved.

## Code of Conduct

This project is governed by the [Contributor Covenant Code of Conduct](https://github.com/hashgraph/.github/blob/main/CODE_OF_CONDUCT.md). By participating, you are
expected to uphold this code of conduct.

## License

[Apache License 2.0](LICENSE)
