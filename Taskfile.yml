version: 3
output: prefixed
dotenv:
  - .env
silent: false

env:
  SOLO_CHART_VERSION: 0.34.0
  CONSENSUS_NODE_VERSION: v0.56.0
  SOLO_NAMESPACE: solo-{{ env "USER" | replace "." "-" | trunc 63 | default "test" }}
  SOLO_CLUSTER_SETUP_NAMESPACE: solo-setup
  SOLO_CLUSTER_RELEASE_NAME: solo-cluster-setup
  SOLO_NETWORK_SIZE: 2
  SOLO_CLUSTER_NAME: solo-cluster
  KIND_IMAGE: kindest/node:v1.27.3@sha256:3966ac761ae0136263ffdb6cfd4db23ef8a83cba8a463690e98317add2c9ba72
  MIRROR_RELEASE_NAME: mirror

vars:
  nodes:
    ref: until (env "SOLO_NETWORK_SIZE" | default .SOLO_NETWORK_SIZE | int)
  # node name should be node1, node2, node3, etc.
  node_list_internal: "{{range $idx, $n := .nodes }}node{{add $n 1}},{{end}}"
  node_identifiers: "{{ .node_list_internal | trimSuffix \",\" }}"

  solo_user_dir: "{{ env \"HOME\" }}/.solo"
  solo_cache_dir: "{{ .solo_user_dir }}/cache"
  solo_logs_dir: "{{ .solo_user_dir }}/logs"
  solo_keys_dir: "{{ .solo_cache_dir }}/keys"
  solo_bin_dir: "{{ .solo_user_dir }}/bin"

tasks:
  readme:
    silent: true
    cmds:
      - echo "This is a custom network configuration for the Hedera Hashgraph Solo network."
      - echo "The network is configured to have {{ .SOLO_NETWORK_SIZE }} nodes."
      - echo "The network is deployed in the namespace {{ .SOLO_NAMESPACE }}."
      - echo "The cluster is deployed in the namespace {{ .SOLO_CLUSTER_SETUP_NAMESPACE }}."
      - echo "Use command 'task default' to deploy the network."
      - echo "Use command 'task destroy' to destroy the network."
      - echo "Use command 'task clean' to destroy and clean up the network."
      - echo "Use command 'task show:ips' to show the external IPs of the nodes."
      - echo "Use command 'task default-with-mirror' to deploy the network with a mirror node."
      - echo "Use command 'task default-with-relay' to deploy the network with a relay node."

  default:
    cmds:
      - task: "install:solo"
      - task: "install"
      - task: "start"

  default-with-mirror:
    cmds:
      - task: "default"
      - task: "mirror:deploy"

  default-with-relay:
    cmds:
      - task: "default"
      - task: "mirror:deploy"
      - task: "solo:relay:deploy"

  install:
    cmds:
      - task: "cluster:create"
      - task: "solo:init"
      - task: "cluster:setup"
      - task: "solo:keys"
      - task: "solo:network:deploy"

  cluster:create:
    status:
      - kind get clusters | grep -q "${SOLO_CLUSTER_NAME}"
    cmds:
      - kind create cluster -n "${SOLO_CLUSTER_NAME}" --image "${KIND_IMAGE}"

  cluster:setup:
    cmds:
      - npm run solo-test -- cluster setup --cluster-setup-namespace "${SOLO_CLUSTER_SETUP_NAMESPACE}"

  cluster:destroy:
    cmds:
      - kind delete cluster --name "${SOLO_CLUSTER_NAME}"

  start:
    cmds:
      - task: "solo:node:start"

  stop:
    cmds:
      - task: "solo:node:stop"

  mirror:deploy:
    cmds:
      - npm run solo-test -- mirror-node deploy --namespace "${SOLO_NAMESPACE}"
      - echo "Enable port forwarding for Hedera Explorer"
      - kubectl port-forward svc/hedera-explorer -n "${SOLO_NAMESPACE}" 8080:80 &
      - task: "sleep_after_port_forward"

  mirror:destroy:
    status:
      - helm list -n "${SOLO_NAMESPACE}" | grep -vqz "${MIRROR_RELEASE_NAME}"
    cmds:
      - npm run solo-test -- mirror-node destroy --namespace "${SOLO_NAMESPACE}" --force || true

  show:ips:
    cmds:
      - task: "solo:node:addresses"

  destroy:
    cmds:
      - task: "solo:node:stop"
      - task: "solo:network:destroy"
      - task: "mirror:destroy"
      - task: "solo:relay:destroy"
      - task: "cluster:destroy"

  clean:
    cmds:
      - task: "destroy"
      - task: "clean:cache"
      - task: "clean:logs"
      - task: "solo:config:remove"

  clean:cache:
    cmds:
      - task: "solo:cache:remove"

  clean:logs:
    cmds:
      - task: "solo:logs:remove"

  solo:init:
    internal: true
    status:
      - test -f {{ .solo_bin_dir }}/helm
      - test -f {{ .solo_cache_dir }}/profiles/custom-spec.yaml
      - test -f {{ .solo_cache_dir }}/templates/api-permission.properties
      - test -f {{ .solo_cache_dir }}/templates/application.properties
      - test -f {{ .solo_cache_dir }}/templates/bootstrap.properties
      - test -f {{ .solo_cache_dir }}/templates/settings.txt
      - test -f {{ .solo_cache_dir }}/templates/log4j2.xml
      #- test "$(yq -r '.flags."node-ids"' < {{ .solo_user_dir }}/solo.yaml)" == "{{ .node_identifiers }}"
      - test "$(jq -r '.flags."node-ids"' < {{ .solo_user_dir }}/solo.config)" == "{{ .node_identifiers }}"
    cmds:
      - npm run solo-test -- init

  solo:keys:
    internal: true
    status:
      - |
         for n in $(seq 0 {{ sub (env "SOLO_NETWORK_SIZE" | default .SOLO_NETWORK_SIZE | int) 1 }}); do
          test -f {{ .solo_keys_dir }}/hedera-node${n+1}.crt
          test -f {{ .solo_keys_dir }}/hedera-node${n+1}.key
          test -f {{ .solo_keys_dir }}/s-public-node${n+1}.pem
          test -f {{ .solo_keys_dir }}/s-private-node${n+1}.pem
         done
    cmds:
      - npm run solo-test -- node keys --gossip-keys --tls-keys --node-aliases-unparsed {{.node_identifiers}}

  solo:network:deploy:
    internal: true
    cmds:
      - npm run solo-test -- network deploy --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} --release-tag "${CONSENSUS_NODE_VERSION}" --solo-chart-version "${SOLO_CHART_VERSION}"
      - npm run solo-test -- node setup --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} --release-tag "${CONSENSUS_NODE_VERSION}"

  solo:network:destroy:
    internal: true
    cmds:
      - npm run solo-test -- network destroy --namespace "${SOLO_NAMESPACE}" --delete-pvcs --delete-secrets --force

  solo:node:start:
    internal: true
    cmds:
      - npm run solo-test -- node start --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} {{ .CLI_ARGS }}
      - kubectl port-forward svc/haproxy-node1-svc -n "${SOLO_NAMESPACE}" 50211:50211 &
      - task: "sleep_after_port_forward"

  solo:node:stop:
    internal: true
    ignore_error: true
    cmds:
      - npm run solo-test -- node stop --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} {{ .CLI_ARGS }}

  solo:node:addresses:
    internal: true
    cmds:
      - kubectl get svc -n "${SOLO_NAMESPACE}" -l "solo.hedera.com/type=network-node-svc"

  solo:relay:deploy:
    cmds:
      - npm run solo-test -- relay deploy -n "${SOLO_NAMESPACE}" -i node1
      - echo "Enable port forwarding for Hedera JSON RPC Relay"
      - kubectl port-forward svc/relay-node1-hedera-json-rpc-relay -n "${SOLO_NAMESPACE}" 7546:7546 &
      - task: "sleep_after_port_forward"

  solo:relay:destroy:
    status:
      - helm list -n "${SOLO_NAMESPACE}" | grep -vqz relay-node1
    cmds:
      - npm run solo-test -- relay destroy -n "${SOLO_NAMESPACE}" -i node1

  solo:cache:remove:
    internal: true
    status:
      - test [[ ! -d {{ .solo_cache_dir }} ]]
    cmds:
      - rm -rf {{ .solo_cache_dir }}

  solo:logs:remove:
    internal: true
    status:
      - test [[ ! -d {{ .solo_logs_dir }} ]]
    cmds:
      - rm -rf {{ .solo_logs_dir }}

  solo:config:remove:
    internal: true
    status:
      - test [[ ! -f {{ .solo_user_dir }}/solo.yaml ]]
    cmds:
      - rm -rf {{ .solo_user_dir }}/solo.yaml

  install:solo:
    internal: true
    status:
      - command -v solo
    cmds:
      - npm install -g @hashgraph/solo

  sleep_after_port_forward:
    cmds:
      # somehow without the sleep, when port-forward is the last command of a series of tasks, port-forward
      # prematurely killed when task is exiting
    - sleep 4
