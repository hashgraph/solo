##
# Copyright (C) 2023-2024 Hedera Hashgraph, LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##

name: "Test GCS as bucket storage"

on:
  workflow_dispatch:
  workflow_call:

defaults:
  run:
    shell: bash

permissions:
  id-token: write
  contents: read
  actions: read

jobs:
  gcs-storage-test:
    timeout-minutes: 20
    runs-on: solo-linux-large
    strategy:
      fail-fast: false
      matrix:
        storageType: ["gcs_only", "minio_only", "aws_only"]
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@4d991eb9b905ef189e4c376166672c3f2f230481 # v2.11.0
        with:
          egress-policy: audit

      - name: Checkout Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Authenticate to Google Cloud
        id: google-auth
        uses: google-github-actions/auth@71f986410dfbc7added4569d411d040a91dc6935 # v2.1.8
        with:
          workload_identity_provider: "projects/652966097426/locations/global/workloadIdentityPools/solo-bucket-dev-pool/providers/gh-provider"
          service_account: "solo-bucket-reader-writer@solo-bucket-dev.iam.gserviceaccount.com"

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@77e7a554d41e2ee56fc945c52dfd3f33d12def9a # v2.1.4

      - name: Get Current Job Log URL
        uses: Tiryoh/gha-jobid-action@v1
        id: jobs
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          job_name: "gcs-storage-test (${{ matrix.storageType }})"

      - name: Create Bucket Name and Prefix
        run: |
          export BUCKET_NAME="solo-ci-test-streams"
          export PREFIX=${{ steps.jobs.outputs.job_id }}

          echo "BUCKET_NAME=${BUCKET_NAME}" >> $GITHUB_ENV
          echo "PREFIX=${PREFIX}" >> $GITHUB_ENV          
          
          export BACKUP_BUCKET_NAME="solo-ci-backups"
          echo "BACKUP_BUCKET_NAME=${BACKUP_BUCKET_NAME}" >> $GITHUB_ENV

      - name: Setup Node
        uses: actions/setup-node@1d0ff469b7ec7b3cb9d8673fde0c81c44821de2a # v4.2.0
        with:
          node-version: 20
          cache: npm

      - name: Setup Helm
        uses: azure/setup-helm@b9e51907a09c216f16ebe8536097933489208112 # v4.3.0
        with:
          version: "v3.12.3" # helm version

      - name: Setup Kind
        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0
        with:
          install_only: true
          node_image: kindest/node:v1.31.4@sha256:2cb39f7295fe7eafee0842b1052a599a4fb0f8bcf3f83d96c7f4864c357c6c30
          version: v0.26.0
          kubectl_version: v1.31.4
          verbosity: 3
          wait: 120s

      - name: Install Dependencies
        id: npm-deps
        run: |
          npm ci
          npm install -g @hashgraph/solo

      - name: Compile Project
        run: npm run build

      - name: Run GCS Test Script for type ${{ matrix.storageType }}
        env:
          GCS_ACCESS_KEY: ${{ secrets.GCP_S3_ACCESS_KEY }}
          GCS_SECRET_KEY: ${{ secrets.GCP_S3_SECRET_KEY }}
          BUCKET_NAME: ${{ env.BUCKET_NAME }}
          PREFIX: ${{ env.PREFIX }}
          BACKUP_BUCKET_NAME: ${{ env.BACKUP_BUCKET_NAME }}/${{ steps.jobs.outputs.job_id }}
          STORAGE_TYPE: ${{ matrix.storageType }}
          GCP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.GCP_SERVICE_ACCOUNT_TOKEN }}
        run: |
          .github/workflows/script/gcs_test.sh

      - name: Delete Test Directory after Test
        if: matrix.storageType == 'gcs_only' || matrix.storageType == 'aws_only'
        run: |
          gcloud storage rm --recursive gs://${BUCKET_NAME}/${{ steps.jobs.outputs.job_id }} --project=${{ vars.GCP_S3_PROJECT_ID }}
          gcloud storage rm --recursive gs://${BACKUP_BUCKET_NAME}/${{ steps.jobs.outputs.job_id }} --project=${{ vars.GCP_S3_PROJECT_ID }}
