##
# Copyright (C) 2023-2024 Hedera Hashgraph, LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##

name: "Test GCS as bucket storage"

on:
  workflow_dispatch:
  workflow_call:

defaults:
  run:
    shell: bash

permissions:
  id-token: write
  contents: read
  actions: read

jobs:
  gcs-storage-test:
    timeout-minutes: 20
    runs-on: solo-linux-large
    strategy:
      matrix:
        storageType: ["gcs_only", "gcs_and_minio"]
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@cb605e52c26070c328afc4562f0b4ada7618a84e # v2.10.4
        with:
          egress-policy: audit

      - name: Checkout Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Authenticate to Google Cloud
        id: google-auth
        uses: google-github-actions/auth@6fc4af4b145ae7821d527454aa9bd537d1f2dc5f # v2.1.7
        with:
          workload_identity_provider: "projects/652966097426/locations/global/workloadIdentityPools/solo-bucket-dev-pool/providers/gh-provider"
          service_account: "solo-bucket-reader-writer@solo-bucket-dev.iam.gserviceaccount.com"

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@6189d56e4096ee891640bb02ac264be376592d6a # v2.1.2

      - name: Get Current Job Log URL
        uses: Tiryoh/gha-jobid-action@v1
        id: jobs
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          job_name: "gcs-storage-test (${{ matrix.storageType }})"

      - name: Create Bucket Name and Prefix
        run: |
          export BUCKET_NAME="solo-ci-test-streams"
          export PREFIX=${{ steps.jobs.outputs.job_id }}

          echo "BUCKET_NAME=${BUCKET_NAME}" >> $GITHUB_ENV
          echo "PREFIX=${PREFIX}" >> $GITHUB_ENV          
          
          export BACKUP_BUCKET_NAME="solo-ci-backups"
          echo "BACKUP_BUCKET_NAME=${BACKUP_BUCKET_NAME}" >> $GITHUB_ENV

      - name: Setup Node
        uses: actions/setup-node@39370e3970a6d050c480ffad4ff0ed4d3fdee5af # v4.1.0
        with:
          node-version: 20
          cache: npm

      - name: Setup Helm
        uses: azure/setup-helm@fe7b79cd5ee1e45176fcad797de68ecaf3ca4814 # v4.2.0
        with:
          version: "v3.12.3" # helm version

      - name: Setup Kind
        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0
        with:
          install_only: true
          node_image: kindest/node:v1.27.3@sha256:3966ac761ae0136263ffdb6cfd4db23ef8a83cba8a463690e98317add2c9ba72
          version: v0.21.0
          kubectl_version: v1.28.6
          verbosity: 3
          wait: 120s

      - name: Install Dependencies
        id: npm-deps
        run: |
          npm ci
          npm install -g @hashgraph/solo

      - name: Compile Project
        run: npm run build

      - name: Run GCS Test Script for type ${{ matrix.storageType }}
        env:
          GCS_ACCESS_KEY: ${{ secrets.GCP_S3_ACCESS_KEY }}
          GCS_SECRET_KEY: ${{ secrets.GCP_S3_SECRET_KEY }}
          BUCKET_NAME: ${{ env.BUCKET_NAME }}
          PREFIX: ${{ env.PREFIX }}
          BACKUP_BUCKET_NAME: ${{ env.BACKUP_BUCKET_NAME }}/${{ steps.jobs.outputs.job_id }}
          STORAGE_TYPE: ${{ matrix.storageType }}
          GCP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.GCP_SERVICE_ACCOUNT_TOKEN }}
        run: |
          .github/workflows/script/gcs_test.sh

      - name: Delete Test Directory after Test
        run: |
          gcloud storage rm --recursive gs://${BUCKET_NAME}/${{ steps.jobs.outputs.job_id }} --project=${{ vars.GCP_S3_PROJECT_ID }}
          gcloud storage rm --recursive gs://${BACKUP_BUCKET_NAME}/${{ steps.jobs.outputs.job_id }} --project=${{ vars.GCP_S3_PROJECT_ID }}
