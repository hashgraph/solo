version: 3
output: prefixed
silent: false
vars:
  nodes:
    ref: until (env "SOLO_NETWORK_SIZE" | default .SOLO_NETWORK_SIZE | int)
  # node name should be node1, node2, node3, etc.
  node_list_internal: "{{range $idx, $n := .nodes }}node{{add $n 1}},{{end}}"
  node_identifiers: "{{ .node_list_internal | trimSuffix \",\" }}"

  solo_user_dir: "{{ env \"HOME\" }}/.solo"
  solo_cache_dir: "{{ .solo_user_dir }}/cache"
  solo_logs_dir: "{{ .solo_user_dir }}/logs"
  solo_keys_dir: "{{ .solo_cache_dir }}/keys"
  solo_bin_dir: "{{ .solo_user_dir }}/bin"

tasks:
  readme:
    silent: true
    cmds:
      - echo "This is a custom network configuration for the Hedera Hashgraph Solo network."
      - echo "The network is configured to have {{ .SOLO_NETWORK_SIZE }} nodes."
      - echo "The network is deployed in the namespace {{ .SOLO_NAMESPACE }}."
      - echo "The cluster is deployed in the namespace {{ .SOLO_CLUSTER_SETUP_NAMESPACE }}."
      - echo "Use command 'task default' to deploy the network."
      - echo "Use command 'task destroy' to destroy the network."
      - echo "Use command 'task clean' to destroy and clean up the network."
      - echo "Use command 'task show:ips' to show the external IPs of the nodes."
      - echo "Use command 'task default-with-mirror' to deploy the network with a mirror node."
      - echo "Use command 'task default-with-relay' to deploy the network with a relay node."

  install:solo:
    internal: true
    status:
      - command -v solo
    cmds:
      - npm install -g @hashgraph/solo
      - cd ../..
      - npm link

  install:kubectl:darwin:
    internal: true
    platforms:
      - darwin
    status:
      - command -v kubectl
    cmds:
      - brew update
      - brew install kubernetes-cli

  install:kubectl:linux:
    internal: true
    platforms:
      - linux
    status:
      - command -v kubectl
    cmds:
      - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/{{ ARCH }}/kubectl"
      - sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
      - rm -rf kubectl

  solo:init:
    internal: true
    status:
      - test -f {{ .solo_bin_dir }}/helm
      - test -f {{ .solo_cache_dir }}/profiles/custom-spec.yaml
      - test -f {{ .solo_cache_dir }}/templates/api-permission.properties
      - test -f {{ .solo_cache_dir }}/templates/application.properties
      - test -f {{ .solo_cache_dir }}/templates/bootstrap.properties
      - test -f {{ .solo_cache_dir }}/templates/settings.txt
      - test -f {{ .solo_cache_dir }}/templates/log4j2.xml
      #- test "$(yq -r '.flags."node-ids"' < {{ .solo_user_dir }}/solo.yaml)" == "{{ .node_identifiers }}"
      - test "$(jq -r '.flags."node-ids"' < {{ .solo_user_dir }}/solo.config)" == "{{ .node_identifiers }}"
    cmds:
      - npm run build
      - solo init

  solo:keys:
    internal: true
    status:
      - |
        for n in $(seq 0 {{ sub (env "SOLO_NETWORK_SIZE" | default .SOLO_NETWORK_SIZE | int) 1 }}); do
         test -f {{ .solo_keys_dir }}/hedera-node${n}.crt
         test -f {{ .solo_keys_dir }}/hedera-node${n}.key
         test -f {{ .solo_keys_dir }}/s-public-node${n}.pem
         test -f {{ .solo_keys_dir }}/s-private-node${n}.pem
        done
    cmds:
      - npm run build
      - solo node keys --gossip-keys --tls-keys --node-aliases-unparsed {{.node_identifiers}}

  solo:network:deploy:
    internal: true
    cmds:
      - npm run build
      - solo network deploy --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} --release-tag "${CONSENSUS_NODE_VERSION}" --solo-chart-version "${SOLO_CHART_VERSION}"
      - solo node setup --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} --release-tag "${CONSENSUS_NODE_VERSION}"

  solo:network:destroy:
    internal: true
    cmds:
      - npm run build
      - solo network destroy --namespace "${SOLO_NAMESPACE}" --delete-pvcs --delete-secrets --force

  solo:node:start:
    internal: true
    cmds:
      - npm run build
      - solo node start --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} {{ .CLI_ARGS }}
      - kubectl port-forward -n "${SOLO_NAMESPACE}" svc/haproxy-node1-svc 50211:50211 &
      - task: "sleep_after_port_forward"

  solo:node:stop:
    internal: true
    ignore_error: true
    cmds:
      - npm run build
      - solo node stop --namespace "${SOLO_NAMESPACE}" --node-aliases-unparsed {{.node_identifiers}} {{ .CLI_ARGS }}

  solo:node:addresses:
    internal: true
    cmds:
      - kubectl get svc -n "${SOLO_NAMESPACE}" -l "solo.hedera.com/type=network-node-svc" --output=go-template-file={{ .ip_list_template_file }}

  solo:relay:
    cmds:
      - npm run build
      - solo relay deploy -n "${SOLO_NAMESPACE}" -i node1
      - echo "Enable port forwarding for Hedera JSON RPC Relay"
      - kubectl port-forward -n "${SOLO_NAMESPACE}" svc/relay-node1-hedera-json-rpc-relay 7546:7546 &
      - task: "sleep_after_port_forward"

  solo:destroy-relay:
    status:
      - helm list -n "${SOLO_NAMESPACE}" | grep -vqz relay-node1
    cmds:
      - npm run build
      - solo relay destroy -n "${SOLO_NAMESPACE}" -i node1

  solo:cache:remove:
    internal: true
    status:
      - test [[ ! -d {{ .solo_cache_dir }} ]]
    cmds:
      - rm -rf {{ .solo_cache_dir }}

  solo:logs:remove:
    internal: true
    status:
      - test [[ ! -d {{ .solo_logs_dir }} ]]
    cmds:
      - rm -rf {{ .solo_logs_dir }}

  solo:config:remove:
    internal: true
    status:
      - test [[ ! -f {{ .solo_user_dir }}/solo.yaml ]]
    cmds:
      - rm -rf {{ .solo_user_dir }}/solo.yaml

  cluster:create:
    status:
      - kind get clusters | grep -q "${SOLO_CLUSTER_NAME}"
    cmds:
      - kind create cluster -n "${SOLO_CLUSTER_NAME}" --image "${KIND_IMAGE}"

  cluster:setup:
    cmds:
      - npm run build
      - solo cluster setup --cluster-setup-namespace "${SOLO_CLUSTER_SETUP_NAMESPACE}"

  cluster:destroy:
    cmds:
      - kind delete cluster --name "${SOLO_CLUSTER_NAME}"

  clean:port-forward:
    cmds:
      - pkill -f "kubectl port-forward -n {{ .SOLO_NAMESPACE }}" || true

  sleep_after_port_forward:
    cmds:
      # somehow without the sleep, when port-forward is the last command of a series of tasks, port-forward
      # prematurely killed when task is exiting
      - sleep 4
